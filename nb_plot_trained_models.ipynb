{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.7 64-bit ('geospatial': virtualenvwrapper)"
  },
  "interpreter": {
   "hash": "0fa17accbb23c72cf25032a422564cfb8a6a73c486c753ed6aa34f37fac56fb6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import folium\n",
    "import pickle\n",
    "from geomodel import geoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "_RUN_DATA = \"data/runs.pkl\"\n",
    "_MODEL_SAVE = \"model_save/model.pt\""
   ]
  },
  {
   "source": [
    "## Load all the running data and the model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(_RUN_DATA,\"rb\") as f:\n",
    "    runs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Embedding(83, 10)\nLinear(in_features=30, out_features=128, bias=True)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "unique_points = 82\n",
    "context_size = 3\n",
    "embedding_dimension = 10\n",
    "model = geoModel(unique_points+1, embedding_dimension, context_size)\n",
    "model.load_state_dict(torch.load(_MODEL_SAVE)[\"model_state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = \"2016-04-07-19-30-19.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = runs[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = run[\"features\"]\n",
    "labels = run[\"labels\"]\n",
    "predicted = model.predict(torch.from_numpy(features)).numpy()\n",
    "points = pd.read_csv(\"data/points.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(array([[26, 70, 37],\n",
       "        [70, 37, 38],\n",
       "        [37, 38, 39],\n",
       "        [38, 39, 40],\n",
       "        [39, 40, 77],\n",
       "        [40, 77, 43],\n",
       "        [77, 43, 42],\n",
       "        [43, 42, 43],\n",
       "        [42, 43, 77],\n",
       "        [43, 77, 41],\n",
       "        [77, 41, 38],\n",
       "        [41, 38, 37],\n",
       "        [38, 37, 36],\n",
       "        [37, 36, 71],\n",
       "        [36, 71, 25],\n",
       "        [71, 25, 27],\n",
       "        [25, 27, 78],\n",
       "        [27, 78, 64],\n",
       "        [78, 64, 67]]),\n",
       " array([38, 39, 40, 77, 43, 42, 43, 77, 41, 38, 37, 36, 71, 25, 27, 78, 64,\n",
       "        67, 74]),\n",
       " array([38, 41, 40, 41, 43, 42, 43, 77, 41, 38, 37, 70, 71, 25, 72, 78, 64,\n",
       "        66, 74]))"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "features, labels, predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}