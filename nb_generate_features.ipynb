{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.7 64-bit ('geospatial': virtualenvwrapper)"
  },
  "interpreter": {
   "hash": "0fa17accbb23c72cf25032a422564cfb8a6a73c486c753ed6aa34f37fac56fb6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import geomodel.processors as gp\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "_MINIMUM_DISTANCE = 40000 # 40KM\n",
    "_POINT_RADIUS = 50/3 # 50 ft approx\n",
    "\n",
    "_columns = ['row','time_stamp','event','event_type','latitude','longitude','altitude','heart_rate','speed','distance','last_event','filename']\n",
    "\n",
    "_DATA_PATH = \"/Users/btb/Documents/Garmin fit Files/data\"\n",
    "_DATA_FILE = \"locations.csv\"\n",
    "_DATA_OUT_PATH = \"data\"\n",
    "\n",
    "data_dict = {}\n",
    "test_keys = [\"2020-05-01-16-58-23.csv\",\"2018-09-30-10-21-14.csv\",\"2020-03-25-17-23-37.csv\",\"2020-05-09-10-11-16.csv\"]"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/btb/.virtualenvs/geospatial/lib/python3.8/site-packages/pandas/compat/__init__.py:97: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n  warnings.warn(msg)\n"
     ]
    }
   ]
  },
  {
   "source": [
    "## Read the close points - we will determine which runs are even \"close\" to the points of interest so we don't interate over unnecessary points\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = pd.read_csv(\"data/points.csv\",names=[\"number\",\"lat\",\"lon\"])\n",
    "close_lats = points[\"lat\"].to_numpy()\n",
    "close_lons = points[\"lon\"].to_numpy()"
   ]
  },
  {
   "source": [
    "## Get all the files"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\"{}/{}\".format(_DATA_PATH,f) for f in os.listdir(_DATA_PATH) if f.endswith(\".csv\")]"
   ]
  },
  {
   "source": [
    "## Process the files and stick them into a dictionary by name of file"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Finished in: 631.480 (s)\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "\n",
    "runs_dictionary = gp.process_files_list(files,_columns,close_lats,close_lons)\n",
    "\n",
    "print(\"Finished in: {0:.3f} (s)\".format(time.time()-t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/runs.pkl\",\"wb\") as f:\n",
    "    pickle.dump(runs_dictionary,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "dict_keys(['file_name', 'data', 'latitude', 'longitude', 'mean_location', 'close_points', 'points_visited', 'point_sequence'])"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "runs_dictionary['2016-01-06-18-45-01.csv'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/runs.pkl\",\"rb\") as f:\n",
    "    runs_dictionary = pickle.load(f)"
   ]
  },
  {
   "source": [
    "## Using a pre-determined lookback \"window\" generate each run's features and labels"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Finished in: 0.088 (s)\n"
     ]
    }
   ],
   "source": [
    "runs = {}\n",
    "t = time.time()\n",
    "for key in runs_dictionary.keys():\n",
    "    if \"point_sequence\" in runs_dictionary[key].keys():\n",
    "        labels, features = gp.generate_label_features(runs_dictionary[key][\"point_sequence\"],window=3)\n",
    "        if len(labels) > 0:\n",
    "            runs[key] = runs_dictionary[key]\n",
    "            runs[key][\"labels\"] = labels\n",
    "            runs[key][\"features\"] = features\n",
    "print(\"Finished in: {0:.3f} (s)\".format(time.time()-t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/runs.pkl\",\"wb\") as f:\n",
    "    pickle.dump(runs,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [k for k in runs.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in runs.keys():\n",
    "    np.save(\"data/model_data/{}.npy\".format(key),np.hstack([runs[key][\"labels\"].reshape(-1,1), runs[key][\"features\"]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_list = pd.DataFrame({\"Files\": l})\n",
    "files_list.to_csv(\"data/runs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'2016-01-06-18-45-01.csv'"
      ]
     },
     "metadata": {},
     "execution_count": 88
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2016-01-06-18-45-01.csv\n2016-01-08-18-16-15.csv\n2016-01-12-18-20-16.csv\n"
     ]
    }
   ],
   "source": [
    "for i,f in files_list.iloc[0:3].iterrows():\n",
    "    print(f[\"Files\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/model_data/{}.npy\".format(key),'rb') as f:\n",
    "    XY1 = np.load(f)\n",
    "\n",
    "with open(\"data/model_data/{}.npy\".format(\"2016-01-12-18-20-16.csv\"),'rb') as f:\n",
    "    XY2 = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([]).reshape(-1,1)\n",
    "Y = np.array([]).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "_append_dispatcher() missing 1 required positional argument: 'values'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-26440297653f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXY1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXY1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXY2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXY2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mappend\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: _append_dispatcher() missing 1 required positional argument: 'values'"
     ]
    }
   ],
   "source": [
    "X = np.append((X, XY1[:,1:]),axis=0)\n",
    "Y = np.append(Y, XY1[:,0])\n",
    "\n",
    "X = np.append((X, XY2[:,1:]),axis=0)\n",
    "Y = np.append(Y, XY2[:,0:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(array([79.,  0.,  3.,  0.,  3., 16.,  3., 16., 14., 16., 14., 12., 14.,\n",
       "        12., 11., 12., 11., 14., 38., 39., 40., 39., 40., 77., 40., 77.,\n",
       "        43., 77., 43., 42., 43., 42., 43., 42., 43., 39., 43., 39., 38.,\n",
       "        39., 38., 37., 38., 37., 70., 37., 70., 26., 70., 26., 27., 26.,\n",
       "        27., 78., 27., 78., 64., 78., 64., 68., 64., 68., 69., 68., 69.,\n",
       "        26., 69., 26., 70., 26., 70., 37., 70., 37., 36.]),\n",
       " (82,))"
      ]
     },
     "metadata": {},
     "execution_count": 83
    }
   ],
   "source": [
    "X, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(array([[16],\n",
       "        [14],\n",
       "        [12],\n",
       "        [11],\n",
       "        [14],\n",
       "        [16]]),\n",
       " array([[79,  0,  3],\n",
       "        [ 0,  3, 16],\n",
       "        [ 3, 16, 14],\n",
       "        [16, 14, 12],\n",
       "        [14, 12, 11],\n",
       "        [12, 11, 14]]))"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "runs[key][\"labels\"].reshape(-1,1), runs[key][\"features\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/btb/.virtualenvs/geospatial/lib/python3.8/site-packages/pandas/compat/__init__.py:97: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open(\"data/runs.pkl\", \"rb\") as f:\n",
    "    runs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.empty(shape=(0,3),dtype=int)\n",
    "Y = np.empty(shape=(0),dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in runs.keys():\n",
    "    if runs[key][\"features\"].shape[0] == runs[key][\"labels\"].shape[0]:\n",
    "        X = np.concatenate((X,runs[key][\"features\"]))\n",
    "        Y = np.concatenate((Y,runs[key][\"labels\"]))\n",
    "    else:\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "runs[key][\"features\"].shape[0] == runs[key][\"labels\"].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"data/data.npy\",np.hstack((Y.reshape(-1,1),X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "XY = np.load(\"data/data.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[41, 77, 43],\n",
       "       [77, 43, 42]])"
      ]
     },
     "metadata": {},
     "execution_count": 51
    }
   ],
   "source": [
    "XY[2:4,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(5743, 1)"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "Y.reshape(-1,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[37, 38, 41],\n",
       "       [38, 41, 77],\n",
       "       [41, 77, 43],\n",
       "       [77, 43, 42],\n",
       "       [43, 42, 43],\n",
       "       [42, 43, 77],\n",
       "       [43, 77, 41],\n",
       "       [77, 41, 38],\n",
       "       [41, 38, 37],\n",
       "       [38, 37, 70],\n",
       "       [37, 70, 26],\n",
       "       [70, 26, 27],\n",
       "       [26, 27, 78],\n",
       "       [27, 78, 64],\n",
       "       [78, 64, 68],\n",
       "       [64, 68, 69],\n",
       "       [26, 70, 37]])"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.vstack([X1,X2[0,:]])"
   ]
  },
  {
   "source": [
    "## Generate a comprehenisve list of features and labels for PyTorch processing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Finished in: 0.002 (s)\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "labels_list = []\n",
    "features_list = []\n",
    "for key in runs.keys():\n",
    "    if \"labels\" in runs[key].keys():\n",
    "        if len(runs[key][\"labels\"]) > 0:\n",
    "            labels_list.append(runs[key][\"labels\"])\n",
    "            features_list.append(runs[key][\"features\"])\n",
    "print(\"Finished in: {0:.3f} (s)\".format(time.time()-t))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.concatenate(labels_list)\n",
    "features = np.concatenate(features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"{}/labels.npy\".format(_DATA_OUT_PATH),labels)\n",
    "np.save(\"{}/features.npy\".format(_DATA_OUT_PATH),features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(5742, 5742)"
      ]
     },
     "metadata": {},
     "execution_count": 68
    }
   ],
   "source": [
    "len(labels), len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}