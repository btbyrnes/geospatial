{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.7 64-bit ('geospatial': virtualenvwrapper)"
  },
  "interpreter": {
   "hash": "0fa17accbb23c72cf25032a422564cfb8a6a73c486c753ed6aa34f37fac56fb6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import geomodel.processors as gp\n",
    "import time\n",
    "\n",
    "_MINIMUM_DISTANCE = 40000 # 40KM\n",
    "_POINT_RADIUS = 50/3 # 50 ft approx\n",
    "\n",
    "_columns = ['row','time_stamp','event','event_type','latitude','longitude','altitude','heart_rate','speed','distance','last_event','filename']\n",
    "\n",
    "_DATA_PATH = \"/Users/btb/Documents/Garmin fit Files/data\"\n",
    "_DATA_FILE = \"locations.csv\"\n",
    "_DATA_OUT_PATH = \"data\"\n",
    "\n",
    "data_dict = {}\n",
    "test_keys = [\"2020-05-01-16-58-23.csv\",\"2018-09-30-10-21-14.csv\",\"2020-03-25-17-23-37.csv\",\"2020-05-09-10-11-16.csv\"]"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/btb/.virtualenvs/geospatial/lib/python3.8/site-packages/pandas/compat/__init__.py:97: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n  warnings.warn(msg)\n"
     ]
    }
   ]
  },
  {
   "source": [
    "## Read the close points - we will determine which runs are even \"close\" to the points of interest so we don't interate over unnecessary points\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = pd.read_csv(\"data/points.csv\",names=[\"number\",\"lat\",\"lon\"])\n",
    "close_lats = points[\"lat\"].to_numpy()\n",
    "close_lons = points[\"lon\"].to_numpy()"
   ]
  },
  {
   "source": [
    "## Get all the files"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\"{}/{}\".format(_DATA_PATH,f) for f in os.listdir(_DATA_PATH) if f.endswith(\".csv\")]"
   ]
  },
  {
   "source": [
    "## Process the files and stick them into a dictionary by name of file"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Finished in: 778.931 (s)\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "\n",
    "runs_dictionary = gp.process_files_list(files,_columns,close_lats,close_lons)\n",
    "\n",
    "print(\"Finished in: {0:.3f} (s)\".format(time.time()-t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"data/runs.pkl\",\"wb\") as f:\n",
    "    pickle.dump(runs_dictionary,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/runs.pkl\",\"rb\") as f:\n",
    "    runs = pickle.load(f)"
   ]
  },
  {
   "source": [
    "## Using a pre-determined lookback \"window\" generate each run's features and labels"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Finished in: 0.029 (s)\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "for key in runs.keys():\n",
    "    if \"point_sequence\" in runs[key].keys():\n",
    "        labels, features = gp.generate_label_features(runs[key][\"point_sequence\"],window=3)\n",
    "        runs[key][\"labels\"] = labels\n",
    "        runs[key][\"features\"] = features\n",
    "print(\"Finished in: {0:.3f} (s)\".format(time.time()-t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/runs.pkl\",\"wb\") as f:\n",
    "    pickle.dump(runs,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(array([16, 14, 12, 11, 14, 16]),\n",
       " array([[79,  0,  3],\n",
       "        [ 0,  3, 16],\n",
       "        [ 3, 16, 14],\n",
       "        [16, 14, 12],\n",
       "        [14, 12, 11],\n",
       "        [12, 11, 14]]))"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "runs[key][\"labels\"], runs[key][\"features\"]"
   ]
  },
  {
   "source": [
    "## Generate a comprehenisve list of features and labels for PyTorch processing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Finished in: 0.002 (s)\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "labels_list = []\n",
    "features_list = []\n",
    "for key in runs.keys():\n",
    "    if \"labels\" in runs[key].keys():\n",
    "        if len(runs[key][\"labels\"]) > 0:\n",
    "            labels_list.append(runs[key][\"labels\"])\n",
    "            features_list.append(runs[key][\"features\"])\n",
    "print(\"Finished in: {0:.3f} (s)\".format(time.time()-t))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.concatenate(labels_list)\n",
    "features = np.concatenate(features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"{}/labels.npy\".format(_DATA_OUT_PATH),labels)\n",
    "np.save(\"{}/features.npy\".format(_DATA_OUT_PATH),features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(5742, 5742)"
      ]
     },
     "metadata": {},
     "execution_count": 68
    }
   ],
   "source": [
    "len(labels), len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}